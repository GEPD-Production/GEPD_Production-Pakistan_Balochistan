{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .str accessor with string values!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 34\u001b[0m\n\u001b[0;32m     30\u001b[0m teacher_roster \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_stata(save_input_folder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mteacher_absence.dta\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Preprocess columns\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m teacher_roster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschool_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mteacher_roster\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mschool_code\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     35\u001b[0m teacher_roster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteacher_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m teacher_roster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm2saq2\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     36\u001b[0m teacher_roster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteacher_unique_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m teacher_roster[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mteachers_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hersheena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:5902\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5895\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5896\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5898\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5899\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5900\u001b[0m ):\n\u001b[0;32m   5901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hersheena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\accessor.py:182\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[1;32m--> 182\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[1;32mc:\\Users\\Hersheena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:181\u001b[0m, in \u001b[0;36mStringMethods.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstring_\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StringDtype\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_categorical \u001b[38;5;241m=\u001b[39m is_categorical_dtype(data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(data\u001b[38;5;241m.\u001b[39mdtype, StringDtype)\n",
      "File \u001b[1;32mc:\\Users\\Hersheena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:235\u001b[0m, in \u001b[0;36mStringMethods._validate\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    232\u001b[0m inferred_dtype \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39minfer_dtype(values, skipna\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inferred_dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed_types:\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .str accessor with string values!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inferred_dtype\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
     ]
    }
   ],
   "source": [
    "#Uncomment the command below to install fuzzywuzzy on your machine\n",
    "#!pip install fuzzywuzzy[speedup]\n",
    "\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "import time\n",
    "start_time = time.time()\n",
    "# Note that this script takes 4 minutes to run\n",
    "\n",
    "#set paths\n",
    "\n",
    "# Enter the country you are running the fuzzy match for here:\n",
    "countries=[\"PAK_Balochistan\"]\n",
    "    \n",
    "#Enter the same file path you have under {$clone} here:\n",
    "project_folder  = \"C:/Users/Hersheena/OneDrive/Desktop/Professional/WBG_GEPD_2023/GEPD Production Balochistan/\"\n",
    "\n",
    "#These paths DO NOT CHANGE\n",
    "save_input_folder = project_folder + \"01_GEPD_raw_data\\School\\Cleaned_teacher_modules\"\n",
    "save_output_folder = project_folder + \"01_GEPD_raw_data\\School\\Cleaned_teacher_modules\"\n",
    "   \n",
    "\n",
    "# # Define a function to calculate the similarity score between two strings\n",
    "# def get_similarity_score(str1, str2):\n",
    "#     return fuzz.token_set_ratio(str1, str2)\n",
    "\n",
    "# Load the two dataframes into Python\n",
    "teacher_roster = pd.read_stata(save_input_folder + \"/\" + \"teacher_absence.dta\")\n",
    "\n",
    "\n",
    "# Preprocess columns\n",
    "teacher_roster['school_name'] = teacher_roster['school_code']\n",
    "teacher_roster['teacher_name'] = teacher_roster['m2saq2'].str.lower().str.strip()\n",
    "teacher_roster['teacher_unique_id'] = teacher_roster['teachers_id']\n",
    "\n",
    "#keep just three columns\n",
    "teacher_roster = teacher_roster[['school_code', 'school_name', 'teacher_name', 'teacher_unique_id', 'm2saq2', 'teachers_id']]\n",
    "\n",
    "# create a unique id that concatenates school code and teachers id\n",
    "#unique_teach_id = teacher_roster['teachers_id'].map(str) + \", \" + teacher_roster['school_code']\n",
    "\n",
    "#teacher pedagogy\n",
    "teacher_pedagogy = pd.read_stata(save_input_folder + \"/\" + \"teacher_pedagogy.dta\")\n",
    "\n",
    "teacher_pedagogy['school_name'] = teacher_pedagogy['school_code']\n",
    "teacher_pedagogy['teacher_name'] = teacher_pedagogy['m4saq1'].str.lower().str.strip()\n",
    "teacher_pedagogy['teacher_unique_id'] = teacher_pedagogy['m4saq1_number']\n",
    "\n",
    "#keep just three columns\n",
    "teacher_pedagogy = teacher_pedagogy[['school_code', 'school_name', 'teacher_name', 'teacher_unique_id', 'm4saq1', 'm4saq1_number']]\n",
    "\n",
    "#teacher content knowedge\n",
    "teacher_content = pd.read_stata(save_input_folder + \"/\" + \"teacher_assessment.dta\")\n",
    "\n",
    "teacher_content['school_name'] = teacher_content['school_code']\n",
    "teacher_content['teacher_name'] = teacher_content['m5sb_troster'].str.lower().str.strip()\n",
    "teacher_content['teacher_unique_id'] = teacher_content['m5sb_tnumber']\n",
    "\n",
    "#keep just three columns\n",
    "teacher_content = teacher_content[['school_code', 'school_name', 'teacher_name', 'teacher_unique_id', 'm5sb_troster', 'm5sb_tnumber']]\n",
    "\n",
    "#teacher questionaire\n",
    "teacher_questionaire = pd.read_stata(save_input_folder + \"/\" + \"teacher_questionnaire.dta\")\n",
    "\n",
    "teacher_questionaire['school_name'] = teacher_questionaire['school_code']\n",
    "teacher_questionaire['teacher_name'] = teacher_questionaire['m3sb_troster'].str.lower().str.strip()\n",
    "teacher_questionaire['teacher_unique_id'] = teacher_questionaire['m3sb_tnumber']\n",
    "\n",
    "#keep just three columns\n",
    "teacher_questionaire = teacher_questionaire[['school_code', 'school_name', 'teacher_name', 'teacher_unique_id', 'm3sb_troster', 'm3sb_tnumber']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#turn the last code into a function with two incputs: df1 and df2\n",
    "def fuzzy_teacher_match(df1, df2):\n",
    "    # Create an empty list to store matches\n",
    "    matches = []\n",
    "\n",
    "    # Loop over each row in df1 and find the best match in df2\n",
    "    for idx1, row1 in df1.iterrows():\n",
    "        best_match_score = -1\n",
    "        best_match_idx = -1\n",
    "        \n",
    "        for idx2, row2 in df2.iterrows():\n",
    "            # Calculate a fuzzy match score for school names and teacher names\n",
    "            school_name_score = fuzz.ratio(row1['school_name'], row2['school_name'])\n",
    "            teacher_name_score = fuzz.ratio(row1['teacher_name'], row2['teacher_name'])\n",
    "            \n",
    "            # if school match score is 100, and teacher match score higher than current best match score, update the best match\n",
    "            if school_name_score == 100 and teacher_name_score > best_match_score:\n",
    "                best_match_score = teacher_name_score\n",
    "                best_match_idx = idx2\n",
    "                        \n",
    "        # If the best match score is above a threshold, consider the two rows a match and add them to the matches list\n",
    "        if best_match_score > 80:\n",
    "            matches.append((idx1, best_match_idx))\n",
    "            \n",
    "    # Create a new data frame to store the merged data\n",
    "    merged_df = pd.DataFrame()\n",
    "\n",
    "    # Loop over each pair of matching rows and merge the data\n",
    "    for match in matches:\n",
    "        merged_row = pd.concat([df1.loc[match[0]], df2.loc[match[1]].drop(['school_name', 'teacher_name', 'teacher_unique_id', 'school_code'])])\n",
    "        merged_df = merged_df.append(merged_row, ignore_index=True)\n",
    "\n",
    "\n",
    "    # for any unmatched teachers in df1, left join with df2 on school_code and teacher_unique_id\n",
    "    df1_teachid_matched = df1[~df1.index.isin([match[0] for match in matches])]\n",
    "\n",
    "    #drop teacher_name from df2\n",
    "    df2 = df2.drop(['teacher_name', 'school_name'], axis=1)\n",
    "    df1_teachid_matched = df1_teachid_matched.merge(df2, how='inner', on=['school_code', 'teacher_unique_id'])\n",
    "\n",
    "\n",
    "    #append df1_teachid_matched to merged_df\n",
    "    merged_df = merged_df.append(df1_teachid_matched, ignore_index=True)\n",
    "\n",
    "    # Reset the index of merged_df to avoid duplicates\n",
    "    merged_df = merged_df.reset_index(drop=True)\n",
    "\n",
    "    #add any unmatched teachers to merged_df\n",
    "    df1_unmatched = df1[~df1.index.isin([match[0] for match in matches]) & ~df1.index.isin(df1_teachid_matched.index)]\n",
    "    df1_unmatched = df1_unmatched.reset_index(drop=True)\n",
    "\n",
    "    merged_df = merged_df.append(df1_unmatched, ignore_index=True)\n",
    "\n",
    "    #return the merged_df\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# call the function for the two data frames teacher_roster and teacher_pedagogy\n",
    "merged_pedagogy_df = fuzzy_teacher_match(teacher_roster, teacher_pedagogy)\n",
    "\n",
    "# call the function for the two data frames teacher_roster and teacher_content\n",
    "merged_content_df = fuzzy_teacher_match(teacher_roster, teacher_content)\n",
    "\n",
    "#call the function for the two data frames in teacher_roster and teacher_questionnaire\n",
    "merged_questionnaire_df = fuzzy_teacher_match(teacher_roster, teacher_questionaire)\n",
    "\n",
    "\n",
    "#join merged_pedagogy_df, merged_content, and merged_questionnaire in one file\n",
    "merged_df1 = pd.merge(teacher_roster, merged_pedagogy_df, on=['school_code','school_name', 'teacher_unique_id', 'teachers_id', 'm2saq2'], how=\"outer\")\n",
    "\n",
    "merged_df2 = pd.merge(merged_df1, merged_content_df, on=['school_code','school_name', 'teacher_unique_id', 'teachers_id', 'm2saq2'], how=\"outer\")\n",
    "\n",
    "merged_df = pd.merge(merged_df2, merged_questionnaire_df, on=['school_code', 'school_name', 'teacher_unique_id', 'teachers_id', 'm2saq2'], how=\"outer\")\n",
    "\n",
    "merged_df = merged_df[['school_code', 'teacher_unique_id', 'm2saq2', 'teachers_id', 'm4saq1', 'm4saq1_number', 'm5sb_troster', 'm5sb_tnumber', 'm3sb_troster', 'm3sb_tnumber']]\n",
    "\n",
    "#save merged_df as a csv\n",
    "merged_df.to_stata(save_output_folder + \"/\" + \"teacher_merged.dta\", version=118)\n",
    "\n",
    "print('\\ndone')\n",
    "\n",
    "print(\"Process finished --- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
